---
title: "Text Analyis"
output: github_document
---


# Ivanka Trump Twitter Analysis

the Data is downloaded from (http://www.trumptwitterarchive.com/archive/account/ivankatrump) and saved as a csv file

```{r,echo=FALSE,warning=FALSE}
#Packages that will be used
library(stringr)
library(utils)
library(rebus)
library(tidyverse)
library(lubridate)
library(wordcloud)
```


# Clean data
```{r}
#split date and time
ivanka_trump_twitter <- read_csv("Data/ivanka_trump_twitter.csv")
bday <- str_split(ivanka_trump_twitter$created_at,pattern=" ",simplify=TRUE)

names(bday)[names(bday)=="1"] <- "date"
names(bday)[names(bday)=="2"] <- "time"

#swich the format of date to someting R can read
date <- bday[,1]
date <- as.Date(date,"%m/%d/%y")

time <- bday[,2]

#separate year, month and day
pattern1 <- capture(one_or_more(DGT))  %R% "-" %R% capture(one_or_more(DGT)) %R% "-" %R% capture(DGT %R% DGT)
date1 <- str_match(date,pattern1)
colnames(date1) <- c("date","year","month","day")
```

```{r}
# compose the useful data into a new data frame
library(dplyr)
other_col <- ivanka_trump_twitter %>% select(c(source,text,id_str,is_retweet))
data <- cbind(other_col,date1,time)

```

```{r,warning=FALSE}
# the number of twitter each year
n_tweet <- data %>%
  group_by(year,month) %>%
  mutate(timestamp=ymd(date))

ggplot(n_tweet,aes(x = timestamp,fill=year)) +
  geom_histogram(position = "identity",bins =20,show.legend=FALSE) +
  xlab("")
```

```{r}

# function that cleans data
hashgrep <- function(text) {
  hg <- function(text) {
    result <- ""
    while(text != result) {
      result <- text
      text <- gsub("#[[:alpha:]]+\\K([[:upper:]]+)", " \\1", text, perl = TRUE)
    }
    return(text)
  }
  unname(sapply(text, hg))
}

cleanposts <- function(text) {
  clean_texts <- text %>%
    gsub("<.*>", "", .) %>% # remove emojis
    gsub("&amp;", "", .) %>% # remove &
    gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", .) %>% # remove retweet entities
    gsub("@\\w+", "", .) %>% # remove at people
    hashgrep %>%
    gsub("[[:punct:]]", "", .) %>% # remove punctuation
    gsub("[[:digit:]]", "", .) %>% # remove digits
    gsub("http\\w+", "", .) %>% # remove html links
    iconv(from = "latin1", to = "ASCII", sub="") %>% # remove emoji and bizarre signs
    gsub("[ \t]{2,}", " ", .) %>% # remove unnecessary spaces
    gsub("^\\s+|\\s+$", "", .) %>% # remove unnecessary spaces
    tolower
  return(clean_texts)
}
```

# Tidy data
```{r}
library(dplyr)
text_clean <- data %>% 
  select(text) %>%
  mutate(text_clean = cleanposts(text))
#remove stop words like "the","of","to"

library(tidytext)

tidy_text <- text_clean %>%
  mutate(linenumber=row_number())%>%
  unnest_tokens(word,text_clean) %>%
  anti_join(stop_words)

data_clean <- cbind(text_clean,data[,3:9],data[,1])
data_clean <- as_tibble(data_clean)
data(stop_words)
data_tidy <- data_clean %>%
  select(-text) %>%
  mutate(linenumber = row_number()) %>%
  unnest_tokens(word,text_clean)%>%
  anti_join(stop_words)
```

# Visualization of the data
```{r}
#the most used words
library(ggplot2)
tidy_text %>%
  count(word,sort=TRUE) %>%
  filter(n>500)%>%
  mutate(word=reorder(word,n))%>%
  ggplot(aes(word,n,fill=n))+
  geom_col()+
  xlab(NULL)+
  coord_flip()
```

```{r,warning=FALSE}

names(data_clean)
#words frequency by month

library(wordcloud)
library(dplyr)


par(mfrow = c(3,3))
for(i in seq(2009,2017)){
frequency <- data_tidy %>%
  group_by(year,word) %>%
  filter(year == i) %>%
  count(year,word,sort = T) %>%
  with(wordcloud(word,n,max.words =90,random.order = F, random.color = F, colors=brewer.pal(8, "Dark2")))
}

#As we can see, Ivanka Trump focus on tweet different topics each year. Generally, her tweets focus on her brand "Ivanka Trump" and from 2010~2015, and then focus more on career and life and American life.
```
# Changes in word use
```{r,warning=FALSE}

library(lubridate)

word_by_time <- data_tidy %>%
  mutate(timestamp=ymd(date))%>%
  mutate(time_floor = floor_date(timestamp,unit = "1 month")) %>%
  count(time_floor,word) %>% #The count column tells us how many times that person used that word in that time bin
  ungroup() %>%
  group_by(time_floor)%>%
  mutate(time_total = sum(n)) %>% # the time_total column tells us how many words that person used during that time bin
  group_by(word)%>%
  mutate(word_total = sum(n)) %>% # the word_total column tells us how many times that person used that word over the whole year
  ungroup() %>%
  rename(count = n) %>%
  filter(word_total > 400)

as_tibble(word_by_time)
nested_data <- word_by_time %>%
  nest(-word)

library(purrr)
nested_models <- nested_data %>%
  mutate(models = map(data,~glm(cbind(count,time_total) ~ time_floor, ., family = "binomial")))

library(broom)
slopes <- nested_models %>%
  unnest(map(models,tidy)) %>%
  filter(term == "time_floor") %>%
  mutate(adjusted.p.value = p.adjust(p.value))

top_slopes <- slopes %>%
  filter(adjusted.p.value < 0.1)

word_by_time %>% 
  inner_join(top_slopes,by="word") %>%
  ggplot(aes(time_floor,count/time_total,color=word),show.legend = FALSE) +
  geom_line(size = 0.8) +
  labs(x = NULL, y = "Word Frequency")
```

# Sentiment Analysis
```{r}
library(tidytext)
library(tidyr)
text_s <- data_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(year,index = linenumber %/% 100, sentiment) %>%
  spread(sentiment,n,fill=0) %>%
  mutate(sentiment = positive - negative)

library(ggplot2)
ggplot(text_s, aes(index,sentiment,fill=year)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~year,ncol=3,scales = "free_x")
#Generally, Ivanka Trump tend to use positive words on twitter.
```


```{r}
# Most common positive and negative words
bing_word_counts <- data_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word,sentiment,sort = TRUE) %>%
  ungroup()
bing_word_counts
 
bing_word_counts %>%
  group_by(sentiment) %>%
  filter(word != "trump") %>% # it is related to her name and her brand, should not be used in sentiment analysis
  top_n(10)%>%
  ungroup %>%
  mutate(word=reorder(word,n))%>%
  ggplot(aes(word,n,fill=sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment,scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```
