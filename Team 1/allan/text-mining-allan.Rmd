---
title: "Text Analyis"
output: html_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
```
if (packageVersion("devtools") < 1.6) {
install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

## Package installation
```{r, message=FALSE, warning=FALSE, eval=FALSE}
#install.packages("janeaustenr")  # for book by janeaustenr
#install.packages("gutenbergr")  # for free ebooks
#install.packages("dplyr")  # for data manipulation
#install.packages("stringr")  # for string manupulation
#install.packages("tidytext")  # for text mining
#install.packages("SnowballC") # for text stemming
#install.packages("ggplot2")  # for text stemming
#install.packages("wordcloud") # word-cloud generator 
#install.packages("RColorBrewer") # color palettes
#install.packages("ggrepel") # ggrepel
#install.packages("igraph") # ggrepel
#install.packages("ggraph") # ggrepel
#install.packages("XML") # for web scraping
#install.packages("rebus") # for regex
#install.packages("R.utils")
#install.packages("topicmodels")

if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}
devtools::install_github("bradleyboehmke/harrypotter")
```

## Loading required packages
```{r message=FALSE, warning=FALSE}
library(janeaustenr)
library(gutenbergr)
library(dplyr)
library(stringr)
library(tidytext)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(harrypotter)
library(tidyr)
library(ggrepel)
library(RColorBrewer)
library(igraph)
library(ggraph)
library(rebus)
library(topicmodels)
library(DT)          #Datatable

```
## Reusable functions
```{r  message=FALSE, warning=FALSE}
# this function returns ggplot theme definition ~ this will prevent code duplication
uniform_ggplot_theme <- function(base_size = 12, base_family = "sans"){
  theme_grey(base_size = base_size, base_family = base_family) +
    theme(
      axis.text = element_text(size = 12),
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
      axis.title = element_text(size = 14),
      panel.grid.major = element_line(color = "grey"),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "aliceblue"),
      strip.background = element_rect(fill = "lightgrey", color = "grey", size = 1),
      strip.text = element_text(face = "bold", size = 12, color = "navy"),
      legend.position = "bottom",
      legend.background = element_blank(),
      panel.margin = unit(.5, "lines"),
      panel.border = element_rect(color = "grey", fill = NA, size = 0.5)
    )
}
```

## Merging data from different sources
Let’s start by importing and merging all necessary data required for this analysis
```{r  message=FALSE, warning=FALSE}

# Fetch Book metadata from theGuardian.com e.g publisher, ranking, sales, author e.t.c 
bookMetadata <- read.csv("https://docs.google.com/spreadsheets/d/1dhxblR1Vl7PbVP_mNhwEa3_lfUWiF__xSODLq1W83CA/export?format=csv&id=1dhxblR1Vl7PbVP_mNhwEa3_lfUWiF__xSODLq1W83CA&gid=0")

#web scrape main characters of Harry Potter Series from
library(XML)
library(RCurl)
# download harry potter wikipedia page
hp_wikipedia_site = readLines('https://en.wikipedia.org/wiki/List_of_Harry_Potter_characters')
#define custom stop word used in HP character names data cleaning
custom_stop_words <-  c('Wikipedia','Wikimedia','The','Puppet','Hogwarts','Stories','Through')
# read entire hp_wikipedia_site
harrypotter_characters <- str_match( hp_wikipedia_site, capture (UPPER %R% one_or_more(WRD)) %R% SPC %R% capture(UPPER %R% one_or_more(WRD))) %>%
  as.data.frame() %>% # convert to data frame for easy manipulation
  na.exclude()%>% # remove missing data
  setNames(c( "FullName", "FirstName", "LastName")) %>% # set column names
  arrange(FullName) %>% # arrange
  filter(!FirstName%in%custom_stop_words) %>% # clean data by first name
  filter(!LastName%in%custom_stop_words) %>% # clean data by last name 
  unique() 




# Combine all The Harry Potter books into 1 dataframe and add column which will be used a reference "Title"

book1 <- data_frame(Title="Harry Potter and the Philosopher's Stone", text=philosophers_stone)
book2 <- data_frame(Title="Harry Potter and the Chamber of Secrets", text=chamber_of_secrets)
book3 <- data_frame(Title="Harry Potter and the Prisoner of Azkaban", text=prisoner_of_azkaban)
book4 <- data_frame(Title="Harry Potter and the Goblet of Fire", text=goblet_of_fire)
book5 <- data_frame(Title="Harry Potter and the Order of the Phoenix", text=order_of_the_phoenix)
book6 <- data_frame(Title="Harry Potter and the Half-blood Prince", text=half_blood_prince)
book7 <- data_frame(Title="Harry Potter and the Deathly Hallows", text=deathly_hallows)

# Join BookMetadata and HarryPotter dfs by "Title"
harrypotterSeries <- rbind(book1,book2, book3, book4, book5, book6, book7) %>%
  group_by(Title) %>%
  mutate(Chapter = row_number())%>% # add chapter
  ungroup()%>%
  unnest_tokens(sentence, text, token = "sentences") %>%
  mutate(line = row_number()) # add sentences

head(harrypotterSeries)
```

## Cleaning Data
1. Restructure it in the one-token-per-row format, 

```{r  message=FALSE, warning=FALSE}
harrypotter_tokenized <- harrypotterSeries %>%
  unnest_tokens(word, sentence)

harrypotter_tokenized %>%
  select(Title, Chapter, word) %>%
  head()

```

2. Remove stop words; stop words are words that are not useful for an analysis, typically extremely common words such as "the", "of", "to",

```{r  message=FALSE, warning=FALSE}
harrypotter_clean_tokens <- harrypotter_tokenized %>% 
  anti_join(stop_words)  #remove stop words like "the"
```

## Quantitative and Sentimental Analysis
###Q1. what is the most important charecter based on how much it was mentioned 
```{r  message=FALSE, warning=FALSE}

harrypotter_clean_tokens %>%
  mutate(id = R.utils::capitalize(word)) %>%
  inner_join(harrypotter_characters, by =c(id = "FirstName") ) %>%
  count(FullName,sort= TRUE)  %>%
  top_n(20) %>%
  ggplot() +
    geom_bar(mapping = aes(x = reorder(FullName, n), fill=FullName,
                           y = n),alpha = 0.8, stat = "identity") +
    labs(x = NULL, y = "Count") +
    coord_flip() + ggtitle("Harry Potter Top 20 Characters")+
    theme(legend.position="none")
```


###Q2. what is the most scariest book based on sentiment analysis ?
```{r  message=FALSE, warning=FALSE}

hp_negative_sentiment<-harrypotter_clean_tokens%>%
  inner_join(get_sentiments("bing"), by = "word") %>% # join sentiment
  group_by(Title)%>% # make each row  abook
  count(sentiment, sort = TRUE)%>% # count sentiment
  filter(sentiment=="negative")  #filter by negative sentiment



#plot the graph of harrypotter_clean_tokens
hp_negative_sentiment %>% 
  ggplot(aes(Title,n, fill=Title)) +
  geom_bar(stat="identity")+
  labs(x = NULL, y = "Level") +
  theme(legend.position="none") +
  coord_flip()
# Using bing lexicon, Harry Potter and the Order of the Phoenix is the scariest with about 8k negative sentiments

# supporting data table
datatable(hp_negative_sentiment)

```

###Q3. What the top ten used words in exception to stop words ?
```{r  message=FALSE, warning=FALSE}
word_count <- harrypotter_clean_tokens %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = reorder(word, n))

# supporting data table
datatable(word_count)
```

```{r}
# Visualization of the most common words
word_count_gt_600 <- word_count %>%
  filter(n > 600)


# plot using word cloud

wordcloud(words = word_count_gt_600$word, freq = word_count_gt_600$n, min.freq = 1,
          random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

###Q4. sentiments by books 
```{r  message=FALSE, warning=FALSE}
hp_sentiment_by_book <- harrypotter_clean_tokens%>%
  # join nrc to get sentiment value
  inner_join(get_sentiments("nrc"), by = "word") %>%
  # join nrc to get sentiment score
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Title,sentiment)%>%
  summarise(count=sum(score)) %>%
  arrange(desc(count)) 

hp_sentiment_by_book%>%
  # get top 15 only
  top_n(15) %>% 
  ungroup %>%
  # plot the graph
  ggplot(aes(sentiment, count, fill = Title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "Score") +
  facet_wrap(~Title) +
  coord_flip()
```

###Q5. sentiment by popularity based on www.theguardian.com
```{r  message=FALSE, warning=FALSE}
hp_by_sales<- harrypotter_clean_tokens%>%
  # join nrc to get sentiment value
  inner_join(get_sentiments("nrc"), by = "word") %>%
  # join nrc to get sentiment score
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Title)%>%
  summarise(count=sum(score)) %>%
  mutate(perc_sentiment=(count/sum(count))*2) %>%
  arrange(desc(perc_sentiment))%>%
  inner_join(bookMetadata, by = "Title")%>%
  mutate(sales=as.numeric(gsub(",","",Volume.Sales)))

df<- data.frame(hp_by_sales)
# plot the graph
ggplot(df)  + 
  geom_bar(aes(x=Title, y=sales,  fill=Title),stat="identity")+
  geom_line(aes(x=Title, y=perc_sentiment*max(df$sales)),group=1)+
  geom_point(aes(label=perc_sentiment, x=Title, y=perc_sentiment*max(df$sales)), colour="brown")+
  geom_text(aes(label=sales, x=Title, y=0.97*sales), colour="black")+
  scale_y_continuous(sec.axis = sec_axis(~./max(df$sales)))+
  labs(x = "Book", y = "Sales/Popularity")+
  theme_minimal()+
  theme(
    axis.text.x=element_blank(),
    axis.ticks.x=element_blank())
# looks like sentimental score is proportioal to the sale/Popularity. But there could be a confounding variable existing or sentimental score is just temporal
```

## More Sentimental & Quantitative Analysis

###Q1. Which is the most common word pairs (ngrams) in harry potter series 
```{r  message=FALSE, warning=FALSE}
harrypotterSeries_ngrams <- harrypotterSeries %>%
  unnest_tokens(bigram, sentence, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts <- harrypotterSeries_ngrams %>%
  count(word1, word2, sort = TRUE)

head(bigram_counts)

bigram_counts%>%
  filter(n > 80)%>%
  ggplot(aes(x = reorder(word1, -n), y = reorder(word2, -n), fill = n)) +
  geom_tile(alpha = 0.8, color = "white") +
  coord_flip() +
  theme(legend.position = "right") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "first word in pair",
       y = "second word in pair")

```

###Q2. Analyze the network structure of the word pairs (ngrams) in harry potter series 
```{r  message=FALSE, warning=FALSE}
bigram_graph <- bigram_counts %>%
  filter(n > 60) %>%
  graph_from_data_frame()
# set seed
set.seed(2017)
# define arrow
a <- grid::arrow(type = "closed", length = unit(.10, "inches"))
# generate graph
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "chartreuse", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```


###Q3. Examine how often sentiment-associated words are preceded by “not” or other negating words.

```{r  message=FALSE, warning=FALSE}
# create hp_big_grams object
hp_bigrams_separated  <- harrypotterSeries %>%
  unnest_tokens(bigram, sentence, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  count(word1, word2, sort = TRUE)

negative_words <- c("not", "no", "never", "without")

hp_negated_words  <- hp_bigrams_separated %>%
  # filter by negative words
  filter(word1 %in% negative_words) %>% 
  inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
  count(word2, score, sort = TRUE) %>%
  ungroup()


hp_negated_words %>%
  mutate(contribution = nn * score) %>%
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2, contribution)) %>%
  ggplot(aes(word2, nn * score, fill = nn * score > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Words preceded by \"not\"") +
  ylab("Sentiment score * number of occurrences") +
  coord_flip()
```


###Q4.What is the frequency distribution of words for each Harry Potter Book
```{r  message=FALSE, warning=FALSE}
book_words <- harrypotter_clean_tokens %>%
  count(Title, word, sort = TRUE) %>%
  ungroup()

total_words <- book_words %>% 
  group_by(Title) %>% 
  summarize(total = sum(n))

book_words <- left_join(book_words, total_words)

head(book_words)
ggplot(book_words, aes(n/total, fill = Title)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~Title, ncol = 2, scales = "free_y")

# These plots exhibit similar distributions for all the books, with most of the words occuring rarely and fewer words that occur frequently.
```
###Q5. Does Zipf’s law holds for Harry Potter series? 
```{r  message=FALSE, warning=FALSE}
freq_by_rank <- book_words %>% 
  group_by(Title) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

head(freq_by_rank)
freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = Title)) + 
  geom_line(size = 1.2, alpha = 0.8) + 
  scale_x_log10() +
  scale_y_log10()

# We see that all 7 novels are similar to each other, and that the relationship between rank and frequency does have negative slope. 

```
###Q6. Does  *power law*  holds in Harry Potter series? 
```{r  message=FALSE, warning=FALSE}
rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = Title)) + 
  geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
  geom_line(size = 1.2, alpha = 0.8) + 
  scale_x_log10() +
  scale_y_log10()
# we can see that we have deviations at higher ranks.This is unusual, because the author uses  a lower percentage of the most common words
```

###Q7. How does positive sentiment change over time, Does the author has a specific pattern of control of positive sentiment?
```{r  message=FALSE, warning=FALSE}
# using nrc and afinn to get both sentiment and score
harrypotter_sentiment <- harrypotter_clean_tokens%>%
  inner_join(get_sentiments("nrc"), by = "word") %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(Title, Chapter,sentiment)%>%
  summarise(count=sum(score))

harrypotter_sentiment%>%
  filter(count>0)%>%
  ggplot( aes(x = Chapter, y = count)) + 
  geom_line(size = 1, color = brewer.pal(3, "Set1")[3]) +
  facet_grid(sentiment~.) +
  uniform_ggplot_theme() + 
  theme(
    axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0),
    legend.position = "none") +
  labs(x = "Chapter", y = "Sentiment Value",
       title = "Sentiments Progression (Positive sentiments)")

```

###Q8. How does negative sentiments changes over time? Is there any similarities in the 1st and last chapter?
```{r  message=FALSE, warning=FALSE}

# plot sentiment df 
harrypotter_sentiment%>%
  filter(count<0)%>%
  ggplot( aes(x = Chapter, y = count)) + 
  geom_line(size = 1, color = brewer.pal(3, "Set1")[1]) +
  facet_grid(sentiment~.) +
  uniform_ggplot_theme() + 
  theme(
    axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0),
    legend.position = "none") +
  labs(x = "Chapter", y = "Sentiment Value",
       title = "Sentiments Progression (Negative sentiments)")
```


###Q9. How does sentiment changes over time for each book? Which book has the highest variation?
```{r  message=FALSE, warning=FALSE}


hp_df<- harrypotter_clean_tokens%>%
  inner_join(get_sentiments("bing"), by = "word") %>% # join sentiment
  count(Title, Chapter, sentiment, sort = TRUE)%>% # count sentiment
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

ggplot(hp_df, aes(Chapter, sentiment, fill = Title))+
  geom_line(size = 1, color = brewer.pal(3, "Set1")[3]) +
  facet_wrap(~Title, ncol = 2, scales = "free_x")

ggplot(hp_df, aes(Chapter, sentiment, colour = Title))+
  geom_line()+
  theme(
    legend.position ="bottom")
# looks like Harry Potter and the Deathly Hallows has the highest sentimental variation
```

###Q10. How frequently did  the overall top 8 most popular characters appear in the last Book
```{r  message=FALSE, warning=FALSE}
top_n_characters <- harrypotter_clean_tokens %>%
  mutate(id = R.utils::capitalize(word)) %>%
  inner_join(harrypotter_characters, by =c(id = "FirstName") ) %>%
  count(FullName,word,sort= TRUE) %>%
  top_n(9)


harrypotter_clean_tokens %>%
  # get the last book of HP
  filter(Title=='Harry Potter and the Deathly Hallows')%>%
  mutate(id = R.utils::capitalize(word)) %>% # create uniq id 
  # get all characters by first name
  inner_join(harrypotter_characters, by = c(id = "FirstName")) %>%
  count( Chapter, FullName,word, sort = TRUE) %>%
  filter(word %in% as.vector(top_n_characters$word))%>% 
  #plot the graph
  ggplot(aes(Chapter, n, color=word)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ FullName, scales = "free_y") +
  ylab("Frequency of Character")
```

###Q11. What are the top 6 topics discussed in harry potter

```{r  message=FALSE, warning=FALSE}
# include only words and  not characters
hp_topic_model_df <- harrypotter_clean_tokens %>%
  mutate(id = R.utils::capitalize(word)) %>%
  # Remove Characters by 1st name
  anti_join(harrypotter_characters, by =c(id = "FirstName") ) %>% 
  # Remove Characters by last name
  anti_join(harrypotter_characters, by =c(id = "LastName") ) %>% 
  unite(document, Title, Chapter) %>%
  # count token
  count(document,word,sort= TRUE)  %>%
  filter(n > 15)

chapters_dtm <- hp_topic_model_df %>%
  cast_dtm(document, word, n)

chapters_lda <- LDA(chapters_dtm, k = 6, control = list(seed = 4564))

chapter_topics <- tidy(chapters_lda, matrix = "beta")
head(chapter_topics)

chapter_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>% #get only top 10 terms
  ungroup() %>%
  arrange(topic, -beta) %>%
  mutate(term = reorder(term, beta)) %>%
  # generate graph
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

# it is dificult to decode all types of  topics potrayed by the author, because of low LDA k value. Increasing k slows down runtime
```

###Q12. How Does the 6 topics discussed varry from each series of Harry Potter
```{r message=FALSE, warning=FALSE}
tidy(chapters_lda, matrix = "gamma") %>%
  # extract book title
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)%>%
  ggplot( aes(gamma, fill = factor(topic))) +
  geom_histogram() +
  facet_wrap(~title, nrow = 6)
```


# Acknowledgments
Question Template from http://tidytextmining.com 


