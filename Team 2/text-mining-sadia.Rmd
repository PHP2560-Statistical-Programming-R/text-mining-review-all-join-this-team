---
title: "Text Analyis"
output: github_document
---

# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

# Timelines and Task

We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
- Ask questions about the data
- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 


#My textual data: Alice's adventure in wonderland is a fantasy novel written by Lewis Carroll, narrating the story of little "Alice" who fells through the rabbit hole into a fantasy world. The book has total 13 chapters and I am trying to analyze the change of emotions throughout the book as alice expererienced different adventures in her wonderland! Finally, I will compare this book with the books of my other team members to see the sentiments in different genre books


```{r, warning=FALSE, cache=FALSE, echo=FALSE, message=FALSE}
# Loading the libraries and the book
#Install
#install.packages("SnowballC") # for text stemming
#install.packages("wordcloud") # word-cloud generator 
#install.packages("RColorBrewer") # color palettes
#install.packages("gutenbergr")
#install.packages("dplyr")
#install.packages("stringr")
#install.packages("tidytext")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("gridExtra")

# Load
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(gutenbergr)
library(dplyr)
library(tidytext)
library(stringr)
library(ggplot2)
library(tidyr)
library(gridExtra)

alice <- gutenberg_download(751) #download the book by book id in a dataframe
```


```{r, warning=FALSE, echo=FALSE, message=FALSE}
## cleaning the book:
alice_tidy<- alice %>%  
mutate(linenumber = row_number(), chapter = cumsum(str_detect(text,regex("chapter|CHAPTER[\\divxlc]", ignore_case = TRUE)))) %>% #breaks down the book by chapter and stores the line number
filter(chapter >0) %>% unnest_tokens(word, text)
```


```{r,warning=FALSE, echo=FALSE, message=FALSE}
#joining with the sentiment 

alice_tidy_bing<-alice_tidy %>% inner_join((get_sentiments("bing"))) 

alice_bing_total<-alice_tidy_bing %>% group_by(chapter, sentiment) %>% mutate(total_words=n()) %>% distinct(chapter, .keep_all=TRUE) %>% select("chapter", "sentiment", "total_words") # creating a column for total positive and negative words
```

#Questions to answer: 
1. Most common positive and negative words
2. what is the overall emotion/sentiment in the book and how does the negative and positive sentiments changes throughout the chapters? 
3. what is the total proportion of positive and negative sentiments 

```{r, warning=FALSE, echo=FALSE, message=FALSE}
##Plot of most frequent words in each chapter:

alice_tidy_bing %>%
    group_by(chapter) %>%
    count(word) %>%
    # Take the top 5 words for each chapter
    top_n(5) %>%
    ungroup() %>%
    mutate(word = reorder(paste(word, chapter, sep = "__"), n)) %>%
    ggplot(aes(word, n, fill=chapter)) +
    geom_col(show.legend = FALSE) +
    scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
    facet_wrap(~ chapter, , scales = "free") +
    coord_flip() +
    labs(x="", y="Frequency of Words", title="Most Frequent Words in Each Chapter") +
   theme(plot.title = element_text(hjust = 0.5))

```

#what are the top 20 positive and negative words in the book?
```{r, warning=FALSE, echo=FALSE,message=FALSE}
alice_tidy_bing %>% count(word, sentiment) %>% arrange(desc(n)) %>% filter(sentiment == "positive") %>% top_n(20)  
alice_tidy_bing %>% count(word, sentiment) %>% arrange(desc(n)) %>% filter(sentiment == "negative") %>% top_n(20)

#graph to show the frequency distribution of positive and negative words by each chapter
alice_tidy_bing %>% group_by(chapter) %>% count(chapter, sentiment) %>% rename(total_words=n) %>%
#Pyramid plot of each chapter by positive and negative words (word frequency by each chapter):
  ggplot(aes(x = as.factor(chapter), fill = sentiment)) + 
  geom_bar(data=filter(alice_tidy_bing, sentiment == "positive")) + 
  geom_bar(data=filter(alice_tidy_bing, sentiment == "negative"),aes(y=..count..*(-1))) + #aes option aligns the plot to 0 and counts on both side of x axis from 0 to positive
  scale_y_continuous(breaks=seq(-350,350,50),labels=abs(seq(-350,350,50))) + 
  coord_flip() +
  labs(x="Chapter", y="Frequency", title="Frequency distribution of positive and negative sentiments by chapter")

```

#What percents of positive and negative words each chapters have?
```{r, warning=FALSE, echo=FALSE, message=FALSE} 
alice_bing_percent<- alice_bing_total %>% #creating a data frame that contains the percent of positive and negative sentiments over the total sentiments
    group_by(chapter) %>%
    mutate(total = sum(total_words),
         percent = total_words/total) 

#What percent of positive words each chapters have?
alice_bing_percent %>%
    filter(sentiment == "positive") %>%
    arrange(desc(percent)) # the most positive chapters were 13, 6, 3, 1, 11. All the chapters have more than 50% of positive sentiments

#What percent of negative words each chapters have?
alice_bing_percent %>%
    filter(sentiment == "negative") %>%
    arrange(desc(percent))
# the most negative chapters were 8,12,5,7,2. There might be something problem happening in the middle of the book. chapter 1 and 2 looks like to have high percent of positive and negative sentiments. Chapter 13 have the lowest percent of negative words indicating a happy ending

```

```{r, warning=FALSE, echo=FALSE}
#Percentage of positive and negative sentiments throughout the chapter
alice_bing_percent %>%
    ggplot(aes(chapter, percent, color=sentiment)) +
    geom_line(size = 1) +
    geom_smooth(method = "lm", se = FALSE, lty = 2) +
    expand_limits(y = 0) +
    ggtitle("Percentage of positive and negative sentiments by chapter") +
   theme(plot.title = element_text(hjust = 0.5))
# Throughout the chapters positve emotions increasing and negatives are decreasing and it looks like positive words had an abrupt increase at the end of the story.

```

#Scatterplot of sentiment throughout the sections (made-up sections where each section have 50 lines)
```{r, warning=FALSE, echo=FALSE}
dat<-alice_tidy_bing %>%
  count(chapter, section = linenumber %/% 50, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) 

p1<-ggplot(dat, aes(section, sentiment, color=sentiment)) +
  geom_smooth(aes(group=1), method="lm", se=FALSE, color="red") +
    geom_point(shape=1, size=3) +
    scale_colour_gradientn(colours=rainbow(4)) 

poinstToLabel<-c("2", "3", "4", "6", "17", "21", "60", "37", "13", "76","169", "170", "139", "184", "7", "8", "24", "27", "86", "46", "68", "141", "142", "79")

p2<-p1 + geom_text(aes(label=section), color="gray20", 
              data= subset(dat, section %in% poinstToLabel),
              hjust=1.5) 
  
p2 + theme_light() +
  theme(text = element_text(color="gray20"),
        legend.position = "right",
        legend.direction = "vertical", 
        legend.justification = 0.1,
        axis.text = element_text(face="italic"),
        plot.title = element_text(hjust = 0.5)) +
  labs(title="Distribution of sentiments throughout the sections")
```

#Wordcloud of most common words of the book
```{r, warning=FALSE, echo=FALSE}
cloud<-alice_tidy_bing %>% count(word, sentiment) %>% arrange(desc(n)) #data frame for wordcloud
wordcloud(words = cloud$word, freq = cloud$n, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```



```{r, warning=FALSE, echo=FALSE, message=FALSE}
## Comparison with other books
Buddhism<- gutenberg_download(18223)
Bible<- gutenberg_download(10)
Quran<- gutenberg_download(2800)
picture<- gutenberg_download(174)
picture.clean<- picture %>%  mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("chapter [\\divxlc]", ignore_case = TRUE)))) %>% filter(chapter >0) %>% unnest_tokens(word, text)
Bible1<-Bible %>% unnest_tokens(word, text)
Buddhism1<- Buddhism %>% unnest_tokens(word, text)
Quran1<-Quran %>% unnest_tokens(word, text)
```

#Total Sentiment score and score per word of the books
```{r, warning=FALSE, echo=FALSE, message=FALSE}
#sentiment score and comparing with other books
total<-function(df) { #function to calculate the total sentiment score with "afinn" lexicon
  df %>% inner_join(get_sentiments("afinn")) %>% summarise(total= sum(score))
} 
score<-function(df){ #function to calculate the sentiment score per word with "afinn" lexicon
  df %>% inner_join(get_sentiments("afinn")) %>% mutate(total=sum(score)) %>% summarize(score_per_word=sum(score)/nrow(df))
}
alice_total<-total(alice_tidy)
alice_score<-score(alice_tidy)

Bible_total<-total(Bible1) 
Bible_score<-score(Bible1)

Buddhism_total<-total(Buddhism1) 
Buddhism_score<-score(Buddhism1)

Quran_total<-total(Quran1) 
Quran_score<- score(Quran1) 

Picture_total<-total(picture.clean) 
Picture_score<- score(picture.clean)


score<-bind_rows(alice_score, Bible_score,Buddhism_score, Quran_score, Picture_score) %>%   mutate(book=c("Alice's Adventures in Wonderland","Bible","The Essence of Buddhism","Quran", "Picture of Dorian Gray")) 
total<-bind_rows(alice_total, Bible_total, Buddhism_total, Quran_total, Picture_total) %>% mutate(book=c("Bible","The Essence of Buddhism","Quran", "Picture of Dorian Gray", "Alice's Adventures in Wonderland")) 

#plot
score_per_word<-ggplot(score, aes(x=reorder(book, score_per_word) ,y=score_per_word,fill=book)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  xlab("Book") + 
  ylab("Score per word") + 
  ggtitle("Sentiment score per word") +
  coord_flip()+
  theme(plot.title = element_text(hjust = 0.5))

total_score<-ggplot(total,aes(x=reorder(book, total),y=total,fill=book)) + 
  geom_bar(stat = "identity", show.legend = FALSE) + 
  xlab("Book") + 
  ylab("Total score") + 
  ggtitle("Total sentiment score of each book") +
  coord_flip()+
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(total_score, score_per_word)
````

#Change of sentiments throughout the sections in all 5 books
```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.width=10, fig.height=6}
# sentiment in the books throughout the sections (assuming a section has on average 50 lines)
Bible<-Bible1 %>% mutate(linenumber = row_number()) %>% inner_join(get_sentiments("bing")) %>% mutate(book="Bible") 
Picture<-picture.clean %>% inner_join(get_sentiments("bing")) %>% mutate(book="Picture of Dorian Gray")
Buddhism<-Buddhism1 %>% mutate(linenumber = row_number()) %>% inner_join(get_sentiments("bing")) %>% mutate(book="The Essence of Buddhism")
Quran<-Quran1 %>% mutate(linenumber = row_number()) %>% inner_join(get_sentiments("bing")) %>% mutate(book="Quran")
Alice<-alice_tidy %>% inner_join(get_sentiments("bing")) %>% mutate(book="Alice's Adventures in Wonderland")

books<-bind_rows(Bible,Buddhism, Quran, Picture, Alice) 


books %>%
  count(book, index = linenumber %/% 50, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  ggplot(aes(index, sentiment, fill=sentiment)) +
  geom_col() +
  # Separating panels with facet_wrap()
  facet_wrap(~ book, scales = "free_x") +
  scale_fill_gradient(low="blue", high="red") +
  labs(x="Sections of the book (50 lines per section)", y="Overall sentiment", title="Change of sentiments throughout the books", fill="overall sentiment =\npositive-negative") +
  theme(plot.title = element_text(hjust = 0.5))
```




