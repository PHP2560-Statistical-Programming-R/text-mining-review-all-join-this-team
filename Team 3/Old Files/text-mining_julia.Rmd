---
title: "Text Analyis"
output: github_document
---




# Your mission

Perform text analysis.

## Okay, I need more information

Perform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.

## Okay, I need even more information.

Do the above. Can't think of a data source?

- `gutenbergr`
- `AssociatedPress` from the `topicmodels` package
- `NYTimes` or `USCongress` from the `RTextTools` package
- Harry Potter Complete 7 Books text
    ```
    if (packageVersion("devtools") < 1.6) {
  install.packages("devtools")
}

devtools::install_github("bradleyboehmke/harrypotter")
    ```
- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/)
- Scrape tweets using [`twitteR`](https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/)

```{r}
install.packages("devtools")
devtools::install_github("bradleyboehmke/harrypotter")
install.packages("rebus")
```

```{r}
library(harrypotter)
?harrypotter
#How the sentiment changes across the entire book
#What are the most common words by chapter
#Which characters appear the most 
#How the emotion anticipation changes throughout the book
#Word count for each book
```

Analyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.

# Timelines and Task


We will spend the next 2 weeks working on analyzing textual data in R. You will do the following:

- Start with some text based data.
- Clean data and prepare it for analysis
```{r}
library(tidytext)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(rebus)
#clean the data
#make a list of book names
book_names <- list(philosophers_stone, chamber_of_secrets, prisoner_of_azkaban, goblet_of_fire, order_of_the_phoenix, half_blood_prince, deathly_hallows)
#concatenate a vector of names
names(book_names) <- c("philosophers_stone", "chamber_of_secrets", "prisoner_of_azkaban", "goblet_of_fire", "order_of_the_phoenix", "half_blood_prince", "deathly_hallows")

books = vector(mode = "list", length = 7)
#create a for loop to go through the chapters of the books and unnest the text into words
for(i in 1:length(books)){
  data <- data_frame(text = book_names[[i]])
  data <- mutate(data, chapter = c(1:nrow(data)), title = names(book_names)[i])
  data <- data %>%
    unnest_tokens(word, text, to_lower = TRUE)
  books[[i]] <- data
}
#new dataset books
books <- ldply(books, data.frame)
```

- Ask questions about the data

```{r}
#Q1:How the sentiment changes across the entire book
sentiments<- books%>%
  filter (title == "order_of_the_phoenix") %>% 
       inner_join(get_sentiments("afinn")) %>%
       group_by(chapter) %>%
       summarise(n= sum(score))
sentiments

p1 <- ggplot(sentiments, aes(x=chapter, y=n)) +
      geom_line(show.legend = FALSE, size = 0.3) +
      scale_color_brewer(palette = "Set1") +
      geom_smooth(se=FALSE, size = 0.2, linetype = 4)

p1+ theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(),axis.line = element_line(colour = "black") )+
 xlim(1, 38) +
scale_x_continuous(
  breaks = c(1:38)) +
  geom_hline(yintercept = 0)
```




```{r}
#Q2:What are the most common words by chapter
common_words<-books%>%
  #filter for the book in series
  filter(title =="order_of_the_phoenix")%>%
  #eliminate the stop words
  anti_join(stop_words)%>%
  #group by chapter
  group_by(chapter)%>%
  #count the words and sort by most used
  count(word, sort=TRUE)%>%
  #top word for each chapter
  top_n(3)%>%
  #arrange by chapter
  arrange(chapter)
common_words


common_words2 <- common_words %>%
  filter(chapter %in% c(1:15))

ggplot(common_words2, aes(word, n, fill = chapter))+ # I am making a plot that fills in the bar with the most common words
  geom_col(show.legend=FALSE)+ # this makes columns and excludes the legend
  facet_wrap(~chapter, scales="free") + # this feature tells R to make this graph for each chapter
  coord_flip()+ # flip the x and y axis
  ggtitle("Common Words Per Chapter in Order of the Phoenix")

common_words3 <- common_words %>%
  filter(chapter %in% c(16:30))

ggplot(common_words3, aes(word, n, fill = chapter))+ # I am making a plot that fills in the bar with the most common words
  geom_col(show.legend=FALSE)+ # this makes columns and excludes the legend
  facet_wrap(~chapter, scales="free") + # this feature tells R to make this graph for each chapter
  coord_flip()+ # flip the x and y axis
  ggtitle("Common Words Per Chapter in Order of the Phoenix")

common_words4 <- common_words %>%
  filter(chapter %in% c(31:38))

ggplot(common_words4, aes(word, n, fill = chapter))+ # I am making a plot that fills in the bar with the most common words
  geom_col(show.legend=FALSE)+ # this makes columns and excludes the legend
  facet_wrap(~chapter, scales="free") + # this feature tells R to make this graph for each chapter
  coord_flip()+ # flip the x and y axis
  ggtitle("Common Words Per Chapter in Order of the Phoenix")
```

```{r}
#Q3:Which characters appear the most 
# clean data
books = vector(mode = "list", length = 7)
for(i in 1:length(books)){
  # convert text to dataframe
  data <- data_frame(text = book_names[[i]])
  # add column for chapter numbers and title of book
  data <- mutate(data, chapter = c(1:nrow(data)), title = names(book_names)[i])
  # split by word and remove punctuation
  data <- data %>%
  # include upper case words  
    unnest_tokens(word, text, to_lower = FALSE)
  # store clean data to list
  books[[i]] <- data
}

# make one data frame from list of data frames
books <- plyr::ldply(books, data.frame)

most.char <- 
filter(books, title=="order_of_the_phoenix") %>%
select(word) %>% 
# regular expression for character names
filter(str_detect(word, UPPER %R% ANY_CHAR %R% ANY_CHAR %R% ANY_CHAR)) %>%  
# remove words that aren't character names
filter(!(word %in% c("The","They","What","There","It's","Then"))) %>%
filter(word != "Harry's", word != "Professor", word != "Gryffindor") %>%
# get frequency for most popular character names
group_by(word) %>%
dplyr::summarize(count=n()) %>%
arrange(desc(count))

ggplot(most.char[1:9, ],aes(x=reorder(word,count),y=count)) + 
  geom_col(fill="cyan",color="blue") +
  xlab("Characters") +
  ggtitle("Most Popular Characters in Order of the Phoenix") +
# Put frequency labels next to bars  
  geom_text(aes(label = paste0(count)), nudge_y = 1) +
  coord_flip()

```


```{r}
#Q4:How the emotion anticipation changes throughout the book
anticipation_senti<-books %>%
  #filter for the book in the series
  filter(title == "order_of_the_phoenix") %>%
  #join using the lexicon "nrc"
  inner_join(get_sentiments("nrc"))%>%
  #group by chapter
  group_by(chapter)%>%
  #count all sentiments
  count(sentiment)

anticipation<-anticipation_senti%>%
  #ungroup by chapter
    ungroup()%>%
  #filter for anticipation
    filter(sentiment=="anticipation")%>%
  #calculate percentage of anticipation based on title
    mutate(total_anticipation=sum(n), percent=n/total_anticipation)%>%
  arrange(chapter)
anticipation

ggplot(anticipation, aes(x=chapter, y=percent))+
  geom_line(aes(fill=sentiment)) +
  ggtitle("Anticipation Per Chapter in Order of the Phoenix") 
  
```

```{r}
#Q5:word count for each book

#select cleaned data
chapter_words<-books%>%
#filter for the book in the series
  filter(title == "order_of_the_phoenix")%>%
#group by chapter
  group_by(chapter)%>%
#count words
  count()

chapter_words%>%
  ungroup()%>%
  #calculate total words by summing all the chapters after ungrouping
  mutate(total_words=sum(n))

```

```{r}
#Q6:All sentiments in the order of the phoenix

all_senti<-books %>%
  #filter for the book in the series
  filter(title == "order_of_the_phoenix") %>%
  #join uding the nrc lexicon
        right_join(get_sentiments("nrc")) %>%
  #filter to not include any sentiments that are N/A
        filter(!is.na(sentiment)) %>%
  #count all the sentiments present and sort by most popular
        count(sentiment, sort = TRUE)
all_senti

ggplot(all_senti, aes(sentiment, n, fill = sentiment))+ # I am making a plot that fills in the bar with the most common words
  geom_col(show.legend=TRUE)+
  ggtitle("All Sentiments in Order of the Phoenix")
```


- Answer these questions with the data using tables and graphics
- Each group member must have their own unique question that they code the answer for. 

